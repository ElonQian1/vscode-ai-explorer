// src/core/analysis/model/ModelRouter.ts
import * as vscode from 'vscode';
/**
 * ğŸ¤– æ¨¡å‹è·¯ç”±å™¨ - OpenAI â†” æ··å…ƒåŒè·¯æ™ºèƒ½åˆ‡æ¢
 *
 * ç­–ç•¥ï¼š
 * - é¦–é€‰OpenAIï¼ˆè´¨é‡æ›´ç¨³å®šï¼‰
 * - æ··å…ƒå›é€€ï¼ˆæ€§ä»·æ¯”é«˜ï¼Œé•¿æ–‡æœ¬å‹å¥½ï¼‰
 * - è‡ªåŠ¨æ£€æµ‹é…ç½®å¯ç”¨æ€§
 * - æ™ºèƒ½é”™è¯¯æ¢å¤
 */
export class ModelRouter {
    primary;
    secondary;
    primaryHealth = true;
    secondaryHealth = true;
    lastHealthCheck = 0;
    healthCheckInterval = 60000; // 1åˆ†é’Ÿ
    constructor(primary, secondary) {
        this.primary = primary;
        this.secondary = secondary;
    }
    async smartCall(prompt, inputs) {
        await this.checkHealth();
        // æ ¹æ®å¥åº·çŠ¶æ€é€‰æ‹©æ¨¡å‹
        const useSecondary = !this.primaryHealth || this.shouldPreferSecondary(inputs);
        try {
            if (useSecondary && this.secondaryHealth) {
                return await this.secondary.call(prompt, inputs);
            }
            else if (this.primaryHealth) {
                return await this.primary.call(prompt, inputs);
            }
            else if (this.secondaryHealth) {
                return await this.secondary.call(prompt, inputs);
            }
            else {
                throw new Error('æ‰€æœ‰AIæ¨¡å‹éƒ½ä¸å¯ç”¨');
            }
        }
        catch (error) {
            console.warn(`Primary model (${this.primary.name}) failed, trying secondary:`, error);
            // ä¸»æ¨¡å‹å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ¨¡å‹
            if (!useSecondary && this.secondaryHealth) {
                this.primaryHealth = false; // æ ‡è®°ä¸»æ¨¡å‹å¥åº·çŠ¶æ€
                return await this.secondary.call(prompt, inputs);
            }
            else if (useSecondary && this.primaryHealth) {
                this.secondaryHealth = false; // æ ‡è®°å¤‡ç”¨æ¨¡å‹å¥åº·çŠ¶æ€
                return await this.primary.call(prompt, inputs);
            }
            throw error;
        }
    }
    /**
     * ğŸ¥ å¥åº·æ£€æŸ¥
     */
    async checkHealth() {
        const now = Date.now();
        if (now - this.lastHealthCheck < this.healthCheckInterval) {
            return;
        }
        this.lastHealthCheck = now;
        // æ£€æŸ¥é…ç½®æ˜¯å¦å¯ç”¨
        const config = vscode.workspace.getConfiguration('ai-explorer');
        const openaiKey = config.get('openai.apiKey') || process.env.OPENAI_API_KEY;
        const hunyuanKey = config.get('hunyuan.apiKey') || process.env.HUNYUAN_API_KEY;
        this.primaryHealth = !!openaiKey;
        this.secondaryHealth = !!hunyuanKey;
    }
    /**
     * ğŸ¤” å†³ç­–æ˜¯å¦ä¼˜å…ˆä½¿ç”¨å¤‡ç”¨æ¨¡å‹
     */
    shouldPreferSecondary(inputs) {
        const code = inputs.code || '';
        // é•¿æ–‡æœ¬ä¼˜å…ˆç”¨æ··å…ƒï¼ˆæ›´ä¾¿å®œï¼‰
        if (code.length > 5000) {
            return true;
        }
        // æ‰¹é‡åˆ†æä¼˜å…ˆç”¨æ··å…ƒ
        if (Array.isArray(inputs.files) && inputs.files.length > 5) {
            return true;
        }
        return false;
    }
    /**
     * ğŸ“Š è·å–æ¨¡å‹çŠ¶æ€
     */
    getStatus() {
        return {
            primary: { name: this.primary.name, healthy: this.primaryHealth },
            secondary: { name: this.secondary.name, healthy: this.secondaryHealth }
        };
    }
}
/**
 * ğŸ”‘ OpenAIæ¨¡å‹å®ç°
 */
export class OpenAIModel {
    name = 'OpenAI GPT-4';
    maxTokens = 128000;
    apiKey;
    baseUrl;
    constructor() {
        const config = vscode.workspace.getConfiguration('ai-explorer');
        this.apiKey = config.get('openai.apiKey') || process.env.OPENAI_API_KEY;
        this.baseUrl = config.get('openai.baseUrl') || 'https://api.openai.com/v1';
    }
    async call(prompt, inputs) {
        if (!this.apiKey) {
            throw new Error('OpenAI API Key æœªé…ç½®');
        }
        const messages = [
            { role: 'system', content: prompt },
            { role: 'user', content: this.formatInputs(inputs) }
        ];
        const response = await fetch(`${this.baseUrl}/chat/completions`, {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${this.apiKey}`,
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                model: 'gpt-4o-mini',
                messages,
                max_tokens: 4000,
                temperature: 0.1,
                response_format: { type: 'json_object' }
            })
        });
        if (!response.ok) {
            throw new Error(`OpenAI API é”™è¯¯: ${response.status} ${response.statusText}`);
        }
        const data = await response.json();
        return data.choices[0]?.message?.content || '{}';
    }
    formatInputs(inputs) {
        return Object.entries(inputs)
            .map(([key, value]) => `${key}: ${typeof value === 'string' ? value : JSON.stringify(value)}`)
            .join('\n\n');
    }
}
/**
 * ğŸ‡¨ğŸ‡³ è…¾è®¯æ··å…ƒæ¨¡å‹å®ç°
 */
export class HunyuanModel {
    name = 'è…¾è®¯æ··å…ƒ';
    maxTokens = 32000;
    secretId;
    secretKey;
    region = 'ap-beijing';
    constructor() {
        const config = vscode.workspace.getConfiguration('ai-explorer');
        this.secretId = config.get('hunyuan.secretId') || process.env.HUNYUAN_SECRET_ID;
        this.secretKey = config.get('hunyuan.secretKey') || process.env.HUNYUAN_SECRET_KEY;
    }
    async call(prompt, inputs) {
        if (!this.secretId || !this.secretKey) {
            throw new Error('è…¾è®¯æ··å…ƒ SecretId/SecretKey æœªé…ç½®');
        }
        const messages = [
            { Role: 'system', Content: prompt },
            { Role: 'user', Content: this.formatInputs(inputs) }
        ];
        try {
            // ä½¿ç”¨è…¾è®¯äº‘SDK
            const tencentcloud = require('tencentcloud-sdk-nodejs-hunyuan');
            const HunyuanClient = tencentcloud.hunyuan.v20230901.Client;
            const client = new HunyuanClient({
                credential: {
                    secretId: this.secretId,
                    secretKey: this.secretKey,
                },
                region: this.region,
            });
            const params = {
                Model: 'hunyuan-lite',
                Messages: messages,
                Stream: false,
                MaxTokens: 4000,
                Temperature: 0.1,
            };
            const response = await client.ChatCompletions(params);
            return response.Choices[0]?.Message?.Content || '{}';
        }
        catch (error) {
            // SDKä¸å¯ç”¨æ—¶ï¼Œå›é€€åˆ°ç›´æ¥HTTPè°ƒç”¨
            return this.callDirectAPI(prompt, inputs);
        }
    }
    async callDirectAPI(prompt, inputs) {
        // è¿™é‡Œå¯ä»¥å®ç°ç›´æ¥HTTPè°ƒç”¨è…¾è®¯æ··å…ƒAPI
        // æš‚æ—¶æŠ›å‡ºé”™è¯¯ï¼Œæç¤ºç”¨æˆ·å®‰è£…SDK
        throw new Error('è¯·å®‰è£…è…¾è®¯äº‘SDK: npm install tencentcloud-sdk-nodejs-hunyuan');
    }
    formatInputs(inputs) {
        return Object.entries(inputs)
            .map(([key, value]) => `${key}: ${typeof value === 'string' ? value : JSON.stringify(value)}`)
            .join('\n\n');
    }
}
/**
 * ğŸ­ æ¨¡å‹è·¯ç”±å™¨å·¥å‚
 */
export function createModelRouter() {
    const primary = new OpenAIModel();
    const secondary = new HunyuanModel();
    return new ModelRouter(primary, secondary);
}
