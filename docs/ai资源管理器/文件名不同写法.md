analyze_hierarchy_simple.cjs
universal-analysis-status-section.tsx
StepCard.tsx

像这种格式， 应该怎么翻译最好？
我的代码能很好的翻译这些不同的文件名写法吗？

可以把这类“多种命名风格”的英文文件名，统一走一条“**分词 → 词性映射 → 中文语序重组 → 按扩展名加后缀**”的规则链。这样**不依赖 AI**也能给出很自然的中文别名；命中不了再走学习词典/AI 兜底。

下面给你三部分：

1. 这三个具体文件的**推荐翻译**；
2. 规则设计与中文语序**如何组织**；
3. 两个**可直接用**的代码文件（Tokenizer + SmartRuleEngine），把它接到你当前的 `TranslateNodeUseCase` 就行。

---

## 一、这三类文件名的推荐翻译

- `analyze_hierarchy_simple.cjs` → **层级分析（简版）脚本**

  - `analyze/analysis → 分析`（**头部名词**），`hierarchy → 层级`（**修饰名词**），`simple → 简版`（**变体/限定词**），`.cjs → 脚本`（**扩展后缀**）。

- `universal-analysis-status-section.tsx` → **通用分析状态区块组件**

  - `section → 区块`（**头部名词**），其余 `universal/analysis/status` 作为**修饰词**；`.tsx → 组件`。

- `StepCard.tsx` → **步骤卡片组件**

  - `Card → 卡片`（**头部名词**），`Step → 步骤`（**修饰名词**）；`.tsx → 组件`。

> 这些都是**不调用 AI**就能稳定产出的结果；当你的代码里启用“学习词典/AI 兜底”后，遇到特别小众的术语也能自动学会。

---

## 二、规则设计要点（保证各风格都吃得下）

1. **统一分词**：

   - 先按 `- _ .` 分段；
   - 再按驼峰边界拆分：`(?<=[a-z0-9])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])`；
   - 将纯大写段识别为**缩写**（API、HTML、ID…），保留原样或做映射。

2. **词典映射（可扩）**：

   - 名词：`analysis→分析`，`hierarchy→层级`，`status→状态`，`section→区块`，`card→卡片`，`step→步骤`…
   - 形容/限定：`universal→通用`，`simple→简版`，`lite→轻量`，`pro→专业`，`test/spec→测试`，`mock→桩`……

3. **中文语序**：

   - **头部名词**（决定主干）：优先级 `section>card>page>analysis>…`，挑一个做“中心词”；
   - 其他名词/形容放在前面做**修饰**：`[范围/通用] [领域/动作] [状态/属性] + 中心词`；
   - 变体/限定（如 simple/test）放括号：`（简版/测试）`。

4. **扩展名后缀**（可配置）：

   - `.tsx/.jsx → 组件`；`.ts → 模块`；`.js/.mjs/.cjs → 脚本`；`.css/.scss → 样式`；`.md → 文档`。

5. **安全清洗**：替换 `\/:*?"<>|` 为 `·`，限制长度（例如 32 字），避免非法文件名。

---

## 三、直接可用的代码（两文件）

> 复制到你的项目里即可。按你之前的别名：`@shared/*` 自行调整 import。
> 每个文件头已加“文件名注释”，中文注释详细。

### 1) 分词器

```ts
// 文件名: src/shared/naming/NameTokenizer.ts
/**
 * 统一文件名分词：
 * - 支持 kebab/snake/dot/camel/Pascal
 * - 识别缩写（API/HTML/ID…）
 * - 输出 tokens 供规则引擎使用
 */
export type Token = {
  raw: string;
  lower: string;
  type: "word" | "acronym" | "num";
};

export function stripExt(name: string) {
  const i = name.lastIndexOf(".");
  if (i <= 0) return { base: name, ext: "" };
  return { base: name.slice(0, i), ext: name.slice(i + 1).toLowerCase() };
}

export function tokenizeFileName(name: string): {
  tokens: Token[];
  ext: string;
} {
  const { base, ext } = stripExt(name);
  const prim = base.split(/[\-_.]+/g).filter(Boolean);
  const parts = prim.flatMap(splitCamelLike);
  const tokens: Token[] = parts.map((part) => {
    if (/^\d+$/.test(part)) return { raw: part, lower: part, type: "num" };
    if (/^[A-Z]{2,}$/.test(part))
      return { raw: part, lower: part.toLowerCase(), type: "acronym" };
    return { raw: part, lower: part.toLowerCase(), type: "word" };
  });
  return { tokens, ext };
}

function splitCamelLike(s: string): string[] {
  // 在 aB | ABc 处断开，再按非字母数字切
  return s
    .replace(/(?<=[a-z0-9])(?=[A-Z])/g, " ")
    .replace(/(?<=[A-Z])(?=[A-Z][a-z])/g, " ")
    .split(/[^A-Za-z0-9]+/g)
    .filter(Boolean);
}
```

### 2) 智能规则引擎（中文语序重组 + 后缀）

```ts
// 文件名: src/features/explorer-alias/domain/policies/SmartRuleEngine.ts
/**
 * SmartRuleEngine：不依赖 AI 的中文别名生成
 * 流程：分词 → 中/英词典映射 → 选中心词 → 组装中文语序 → 加扩展后缀 → sanitize
 */
import { tokenizeFileName, Token } from "@shared/naming/NameTokenizer";

export type AliasResult = {
  alias: string;
  source: "rule";
  confidence: number;
  debug?: string;
};

const NounMap: Record<string, string> = {
  analysis: "分析",
  analyze: "分析",
  analyzer: "分析器",
  hierarchy: "层级",
  status: "状态",
  section: "区块",
  block: "区块",
  panel: "面板",
  card: "卡片",
  page: "页面",
  view: "视图",
  step: "步骤",
  item: "条目",
  list: "列表",
};

const AdjMap: Record<string, string> = {
  universal: "通用",
  simple: "简版",
  lite: "轻量",
  mini: "迷你",
  basic: "基础",
  advanced: "高级",
  pro: "专业",
  test: "测试",
  spec: "测试",
  mock: "桩",
};

const AcronymMap: Record<string, string> = {
  ui: "UI",
  id: "ID",
  api: "API",
  http: "HTTP",
  url: "URL",
  dom: "DOM",
};

const HeadPriority = [
  "section",
  "block",
  "panel",
  "card",
  "page",
  "view",
  "analysis",
];

const ExtSuffix: Record<string, string> = {
  tsx: "组件",
  jsx: "组件",
  ts: "模块",
  js: "脚本",
  mjs: "脚本",
  cjs: "脚本",
  css: "样式",
  scss: "样式",
  less: "样式",
  md: "文档",
};

export class SmartRuleEngine {
  translate(name: string): AliasResult | undefined {
    const { tokens, ext } = tokenizeFileName(name);
    if (!tokens.length) return;

    // 拆分词性
    const nouns: Array<{ zh: string; en: string }> = [];
    const adjs: Array<{ zh: string; en: string }> = [];
    const others: string[] = [];

    for (const t of tokens) {
      if (t.type === "acronym" && AcronymMap[t.lower]) {
        nouns.push({ zh: AcronymMap[t.lower], en: t.lower });
        continue;
      }
      if (AdjMap[t.lower]) {
        adjs.push({ zh: AdjMap[t.lower], en: t.lower });
        continue;
      }
      if (NounMap[t.lower]) {
        nouns.push({ zh: NounMap[t.lower], en: t.lower });
        continue;
      }
      // 未命中的词也先记下来，后续可作为名词参与
      others.push(t.raw);
    }

    // 选择中心词（Head）
    const nounKeys = nouns.map((n) => n.en);
    let head = nouns.find((n) => HeadPriority.includes(n.en));
    if (!head && nouns.length) head = nouns[nouns.length - 1]; // 最后一个名词作中心
    if (!head && others.length)
      head = {
        zh: others[others.length - 1],
        en: others[others.length - 1].toLowerCase(),
      };

    if (!head) return;

    // 修饰词（去掉中心词）
    const mods: string[] = [];
    // 形容/限定优先
    mods.push(...adjs.map((a) => a.zh));
    // 其余名词（非中心词）
    mods.push(...nouns.filter((n) => n !== head).map((n) => n.zh));

    // 变体/测试一类放括号
    const variants = adjs
      .map((x) => x.en)
      .filter((en) =>
        [
          "simple",
          "lite",
          "mini",
          "basic",
          "advanced",
          "pro",
          "test",
          "spec",
          "mock",
        ].includes(en)
      )
      .map((en) => AdjMap[en]) // 映射中文
      .filter(Boolean);

    const core = `${mods.join("")}${head.zh}` || head.zh;

    const suffix = ExtSuffix[ext] ? ` ${ExtSuffix[ext]}` : "";
    const variantStr = variants.length
      ? `（${Array.from(new Set(variants)).join("、")}）`
      : "";

    const raw = `${core}${variantStr}${suffix}`;
    const alias = sanitize(raw);

    return {
      alias,
      source: "rule",
      confidence: 0.88,
      debug: `tokens=${tokens.map((t) => t.raw).join("|")} head=${
        head.en
      } ext=${ext}`,
    };
  }
}

function sanitize(s: string) {
  return (s || "")
    .replace(/[\\/:*?"<>|]/g, "·")
    .replace(/\s+/g, " ")
    .trim()
    .slice(0, 32);
}
```

> 连接方式：在你的 `TranslateNodeUseCase` 里，把现在的 `RuleEngine` 换成（或并列）`SmartRuleEngine.translate(name)`，未命中词表/学习词典时调用它。命中后仍然写入**路径缓存**即可。

---

## 四、落地接线（两行替换）

```ts
// （示例）src/features/explorer-alias/app/TranslateNodeUseCase.ts 片段
// 原: const byRule = this.rules.apply(name, kind);
// 新:
import { SmartRuleEngine } from "../domain/policies/SmartRuleEngine";
const smart = new SmartRuleEngine();
const byRule = smart.translate(name); // kind 目前不需要；要用也可作为加权因素
if (byRule) {
  this.cache.set(fsPath, byRule);
  return byRule;
}
```

---

## 五、效果预期 & 覆盖面

- **覆盖面**：常见的 `kebab/snake/camel/Pascal + 复合词` 能稳定命中，命名含义清晰的场景可达 **80%+** 的“像人写的中文”。
- **一致性**：同类词会统一口径（如 `section→区块`，`card→卡片`）。
- **可扩**：你只要往 `NounMap/AdjMap` 里补条目，就能定制团队术语。
- **兜底**：命不中再走**学习词典**或 **AI**；AI 产出的新词条会写回词典，之后**零请求**直接命中。

如果你愿意，我可以把这两份代码直接对齐到你仓库的路径结构，并顺手给你加 6 个单元测试（就测你这三类命名 + 常见变体），你一跑就能看到“中文别名”是否稳定产出。
